{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fce4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Entrez import efetch\n",
    "from dicttoxml import dicttoxml\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "import re\n",
    "\n",
    "global entry_data\n",
    "\n",
    "def extract_mesh_terms(raw_mesh_text):\n",
    "    tags = None\n",
    "    t = re.sub('<.*?>', ' ', raw_mesh_text)\n",
    "    t = t.split()\n",
    "    tags = t\n",
    "    return tags\n",
    "    \n",
    "def query_pubmed(pmid_file):\n",
    "    with open(pmid_file, \"r\") as f:\n",
    "        for pmid in f:\n",
    "            pmid = pmid.rstrip()\n",
    "            try:\n",
    "                handle = efetch(db=\"pubmed\", id=pmid, retmode=\"xml\", rettype=\"abstract\")\n",
    "            except:\n",
    "                yield pmid, None\n",
    "            yield pmid, handle.read()\n",
    "            \n",
    "def parse_pubmed_query(raw_text):\n",
    "    title, abstract, medline = \"None\", \"None\", \"None\"\n",
    "    raw_text = \"\".join(raw_text[0].decode(\"utf-8\"))\n",
    "    title_start_idx, title_end_idx = raw_text.find(\"<ArticleTitle>\") + len(\"<ArticleTitle>\"), raw_text.find(\"</ArticleTitle>\") \n",
    "    title = raw_text[title_start_idx:title_end_idx]\n",
    "    abstract_start_idx, abstract_end_idx = raw_text.find(\"<AbstractText>\") + \\\n",
    "        len(\"<AbstractText>\"), raw_text.find(\"</AbstractText>\") \n",
    "    if \"<MeshHeadingList>\" in raw_text:\n",
    "        medline_start_idx, medline_end_idx = raw_text.find(\"<MeshHeadingList>\") + len(\"</MeshHeadingList>\") - 1, \\\n",
    "            raw_text.find(\"</MeshHeadingList>\")\n",
    "        medline = raw_text[medline_start_idx: medline_end_idx]\n",
    "        medline = extract_mesh_terms(medline)\n",
    "    abstract = raw_text[abstract_start_idx:abstract_end_idx]\n",
    "    print(title)\n",
    "    \n",
    "    return {\"title\": title, \"abstract\": abstract, \"medline\": medline}\n",
    "            \n",
    "def pubmed_query_to_train(pmid_file, train_size=10000):\n",
    "    global entry_data\n",
    "    entry_data = dict()\n",
    "    current_idx = 0\n",
    "    for pmid, *data in query_pubmed(pmid_file):\n",
    "        print(current_idx, \"/\", train_size)\n",
    "        try:\n",
    "            data = parse_pubmed_query(data)\n",
    "        except:\n",
    "            data = {\"title\": None, \"abstract\": None, \"medline\": None}\n",
    "        entry_data[pmid] = data\n",
    "        clear_output(wait=True)\n",
    "        current_idx += 1\n",
    "    json_data      = json.dumps(entry_data)\n",
    "        \n",
    "    with open(\"proteomics_output.json\", \"w+\", encoding='utf-8') as out:\n",
    "        out.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d594cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999 / 10000\n",
      "Integration of multi-omics datasets enables molecular classification of COPD.\n"
     ]
    }
   ],
   "source": [
    "def download_pubmed_data(file_path):\n",
    "    pubmed_query_to_train('pmid-proteomics-set.txt')\n",
    "download_pubmed_data(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796b4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from unidecode import unidecode\n",
    "\n",
    "json_data = None\n",
    "\n",
    "with open(\"proteomics_output.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    json_data = json.loads(f.read(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5125f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 846.54it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 1666257.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "tokens = []\n",
    "sentences = []\n",
    "\n",
    "for pmid in tqdm(json_data.keys()):\n",
    "    document_abstract = json_data[pmid][\"abstract\"]\n",
    "    document_mesh     = json_data[pmid][\"medline\"]\n",
    "    document_mesh     = \" \".join(document_mesh)\n",
    "    mesh_tokens       = word_tokenize(document_mesh)\n",
    "    document_tokens   = word_tokenize(document_abstract)\n",
    "    tokens.extend(document_tokens)\n",
    "    tokens.extend(mesh_tokens)\n",
    "    \n",
    "for pmid in tqdm(json_data.keys()):\n",
    "    document_abstract = json_data[pmid][\"abstract\"]\n",
    "    sentences.append(document_abstract)\n",
    "\n",
    "porter_stemmer    = PorterStemmer()\n",
    "pre_tf_idf_tokens = []\n",
    "\n",
    "for word in tokens:\n",
    "    pre_tf_idf_tokens.append(porter_stemmer.stem(word))\n",
    "\n",
    "tf_idf_vec_smooth = TfidfVectorizer(use_idf=True,  \n",
    "                        smooth_idf=True,  \n",
    "                        ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "X_unigram = tf_idf_vec_smooth.fit_transform(pre_tf_idf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91058aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vec_smooth_bigram = TfidfVectorizer(use_idf=True,\n",
    "                                  smooth_idf=True,\n",
    "                                  ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "X_unigram_bigram = tf_idf_vec_smooth_bigram.fit_transform(pre_tf_idf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359e20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import count_nonzero\n",
    "\n",
    "def calculate_sparsity(sparse_matrix):\n",
    "    sparsity = 1.0 - ( count_nonzero(sparse_matrix) / float(sparse_matrix.size) )\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac716569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from unidecode import unidecode\n",
    "\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def is_english_token(token):\n",
    "    if not wordnet.synsets(token):\n",
    "        print(token)\n",
    "        \n",
    "        \n",
    "translator=str.maketrans('','',string.punctuation)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "chemical_translations = {\n",
    "    \"alpha\":\"a\", \"beta\":\"b\", \"gamma\":\"g\", \"delta\":\"d\",\n",
    "    \"epsilon\":\"e\", \"zeta\":\"z\", \"eta\":\"e\", \"theta\":\"th\",\n",
    "    \"iota\":\"i\", \"kappa\":\"k\", \"lambda\":\"l\", \"mu\":\"m\",\n",
    "    \"xi\":\"x\", \"pi\":\"p\", \"rho\":\"r\", \"simga\":\"s\",\n",
    "    \"tau\":\"t\", \"phi\":\"ph\", \"chi\":\"kh\",\"psi\":\"ps\",\n",
    "    \"omega\":\"o\"\n",
    "}\n",
    "chemical_keys = set(chemical_translations)\n",
    "\n",
    "def preprocess_sentence(sentence, translator):\n",
    "    sentence = sentence.lower()\n",
    "    if 'doctype' in sentence: #flagging badly encoded JSON documents\n",
    "        return \"\"\n",
    "    out = sentence.translate(translator)\n",
    "    out = re.sub(\"\\d+\\.?\\d+?\", \"\",  out)\n",
    "    out = re.sub(\"[^\\u0000-\\u05C0\\u2100-\\u214F]+\", \"\", out)\n",
    "    \n",
    "    out = [lemmatizer.lemmatize(token) for token in nltk.word_tokenize(out)]\n",
    "    out = \" \".join(out)\n",
    "    out = unidecode(out)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc03991",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_sentences = [preprocess_sentence(sentence, translator) for sentence in sentences]\n",
    "preprocessed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0fec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_sentences = []\n",
    "\n",
    "for sentence in preprocessed_sentences:\n",
    "    for key, val in chemical_translations.items():\n",
    "        sentence = sentence.replace(key, val)\n",
    "    normalized_sentences.append(sentence)\n",
    "normalized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0acbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 45902)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,1),\n",
    "                           stop_words='english')\n",
    "\n",
    "count_data = count_vectorizer.fit_transform(preprocessed_sentences)\n",
    " \n",
    "cv_dataframe=pd.DataFrame(count_data.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "cv_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6f71d",
   "metadata": {},
   "source": [
    "### Probabilistic Threshing - Dictionary Size\n",
    "    1. Chemical Compound Lists - Not compatiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d973ebc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0h</th>\n",
       "      <th>11</th>\n",
       "      <th>13clysine</th>\n",
       "      <th>14</th>\n",
       "      <th>14bdglucosidic</th>\n",
       "      <th>1a</th>\n",
       "      <th>1a1</th>\n",
       "      <th>1a1b</th>\n",
       "      <th>1a1blight</th>\n",
       "      <th>1acid</th>\n",
       "      <th>...</th>\n",
       "      <th>zyggregator</th>\n",
       "      <th>zygosaccharomyces</th>\n",
       "      <th>zygote</th>\n",
       "      <th>zygotic</th>\n",
       "      <th>zymogen</th>\n",
       "      <th>zymograms</th>\n",
       "      <th>zymographic</th>\n",
       "      <th>zymography</th>\n",
       "      <th>zymoseptoria</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 45902 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0h  11  13clysine  14  14bdglucosidic  1a  1a1  1a1b  1a1blight  1acid  \\\n",
       "0      0   0          0   0               0   0    0     0          0      0   \n",
       "1      0   0          0   0               0   0    0     0          0      0   \n",
       "2      0   0          0   0               0   0    0     0          0      0   \n",
       "3      0   0          0   0               0   0    0     0          0      0   \n",
       "4      0   0          0   0               0   0    0     0          0      0   \n",
       "...   ..  ..        ...  ..             ...  ..  ...   ...        ...    ...   \n",
       "9995   0   0          0   0               0   0    0     0          0      0   \n",
       "9996   0   0          0   0               0   0    0     0          0      0   \n",
       "9997   0   0          0   0               0   0    0     0          0      0   \n",
       "9998   0   0          0   0               0   0    0     0          0      0   \n",
       "9999   0   0          0   0               0   0    0     0          0      0   \n",
       "\n",
       "      ...  zyggregator  zygosaccharomyces  zygote  zygotic  zymogen  \\\n",
       "0     ...            0                  0       0        0        0   \n",
       "1     ...            0                  0       0        0        0   \n",
       "2     ...            0                  0       0        0        0   \n",
       "3     ...            0                  0       0        0        0   \n",
       "4     ...            0                  0       0        0        0   \n",
       "...   ...          ...                ...     ...      ...      ...   \n",
       "9995  ...            0                  0       0        0        0   \n",
       "9996  ...            0                  0       0        0        0   \n",
       "9997  ...            0                  0       0        0        0   \n",
       "9998  ...            0                  0       0        0        0   \n",
       "9999  ...            0                  0       0        0        0   \n",
       "\n",
       "      zymograms  zymographic  zymography  zymoseptoria  zz  \n",
       "0             0            0           0             0   0  \n",
       "1             0            0           0             0   0  \n",
       "2             0            0           0             0   0  \n",
       "3             0            0           0             0   0  \n",
       "4             0            0           0             0   0  \n",
       "...         ...          ...         ...           ...  ..  \n",
       "9995          0            0           0             0   0  \n",
       "9996          0            0           0             0   0  \n",
       "9997          0            0           0             0   0  \n",
       "9998          0            0           0             0   0  \n",
       "9999          0            0           0             0   0  \n",
       "\n",
       "[10000 rows x 45902 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc80455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984680754651214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_sparsity(cv_dataframe.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "755463e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 45902)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vec_smooth = TfidfVectorizer(use_idf=True,  \n",
    "                        smooth_idf=True,  \n",
    "                        ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "X_unigram = tf_idf_vec_smooth.fit_transform(preprocessed_sentences)\n",
    "cv_dataframe_tfidf=pd.DataFrame(X_unigram.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "cv_dataframe_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba267077",
   "metadata": {},
   "source": [
    "Check overlap of terms in documents [High overlap = TF-IDF, Low overlap = CountVectorizer]\n",
    "Kneser-Ney Smoothing might be worth looking into\n",
    "TF-IDF smoothing is just computationally beneficial\n",
    "    -mlwiki smoothing for language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_list_data = []\n",
    "\n",
    "count = 0\n",
    "for pmid in tqdm(json_data.keys()):\n",
    "    chemicals = json_data[pmid][\"medline\"]\n",
    "    chemical_list_data.append(chemicals)\n",
    "    if \"Proteome\" in chemicals:\n",
    "        count += 1\n",
    "chemical_list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a88183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0h</th>\n",
       "      <th>11</th>\n",
       "      <th>13clysine</th>\n",
       "      <th>14</th>\n",
       "      <th>14bdglucosidic</th>\n",
       "      <th>1a</th>\n",
       "      <th>1a1</th>\n",
       "      <th>1a1b</th>\n",
       "      <th>1a1blight</th>\n",
       "      <th>1acid</th>\n",
       "      <th>...</th>\n",
       "      <th>zyggregator</th>\n",
       "      <th>zygosaccharomyces</th>\n",
       "      <th>zygote</th>\n",
       "      <th>zygotic</th>\n",
       "      <th>zymogen</th>\n",
       "      <th>zymograms</th>\n",
       "      <th>zymographic</th>\n",
       "      <th>zymography</th>\n",
       "      <th>zymoseptoria</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45902 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0h   11  13clysine   14  14bdglucosidic   1a  1a1  1a1b  1a1blight  1acid  \\\n",
       "0  0.0  0.0        0.0  0.0             0.0  0.0  0.0   0.0        0.0    0.0   \n",
       "1  0.0  0.0        0.0  0.0             0.0  0.0  0.0   0.0        0.0    0.0   \n",
       "2  0.0  0.0        0.0  0.0             0.0  0.0  0.0   0.0        0.0    0.0   \n",
       "3  0.0  0.0        0.0  0.0             0.0  0.0  0.0   0.0        0.0    0.0   \n",
       "4  0.0  0.0        0.0  0.0             0.0  0.0  0.0   0.0        0.0    0.0   \n",
       "\n",
       "   ...  zyggregator  zygosaccharomyces  zygote  zygotic  zymogen  zymograms  \\\n",
       "0  ...          0.0                0.0     0.0      0.0      0.0        0.0   \n",
       "1  ...          0.0                0.0     0.0      0.0      0.0        0.0   \n",
       "2  ...          0.0                0.0     0.0      0.0      0.0        0.0   \n",
       "3  ...          0.0                0.0     0.0      0.0      0.0        0.0   \n",
       "4  ...          0.0                0.0     0.0      0.0      0.0        0.0   \n",
       "\n",
       "   zymographic  zymography  zymoseptoria   zz  \n",
       "0          0.0         0.0           0.0  0.0  \n",
       "1          0.0         0.0           0.0  0.0  \n",
       "2          0.0         0.0           0.0  0.0  \n",
       "3          0.0         0.0           0.0  0.0  \n",
       "4          0.0         0.0           0.0  0.0  \n",
       "\n",
       "[5 rows x 45902 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dataframe_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee80703",
   "metadata": {},
   "source": [
    "### May want to include as part of Github utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d203560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def co_occurrence(sentences, window_size):\n",
    "    d = defaultdict(int)\n",
    "    vocab = set()\n",
    "    for text in sentences:\n",
    "        # preprocessing (use tokenizer instead)\n",
    "        text = text.lower().split()\n",
    "        # iterate over sentences\n",
    "        for i in range(len(text)):\n",
    "            token = text[i]\n",
    "            vocab.add(token)  # add to vocab\n",
    "            next_token = text[i+1 : i+1+window_size]\n",
    "            for t in next_token:\n",
    "                key = tuple( sorted([t, token]) )\n",
    "                d[key] += 1\n",
    "    \n",
    "    # formulate the dictionary into dataframe\n",
    "    vocab = sorted(vocab) # sort vocab\n",
    "    df = pd.DataFrame(data=np.zeros((len(vocab), len(vocab)), dtype=np.int16),\n",
    "                      index=vocab,\n",
    "                      columns=vocab)\n",
    "    for key, value in d.items():\n",
    "        df.at[key[0], key[1]] = value\n",
    "        df.at[key[1], key[0]] = value\n",
    "    return df\n",
    "\n",
    "co_occurrence_matrix = co_occurrence(normalized_sentences, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fb94d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'ditiodiproponate</th>\n",
       "      <th>(c)</th>\n",
       "      <th>(tm)</th>\n",
       "      <th>*3</th>\n",
       "      <th>*4</th>\n",
       "      <th>*8</th>\n",
       "      <th>+-</th>\n",
       "      <th>+-1</th>\n",
       "      <th>+-2</th>\n",
       "      <th>+-3</th>\n",
       "      <th>...</th>\n",
       "      <th>zyggregator</th>\n",
       "      <th>zygosaccharomyces</th>\n",
       "      <th>zygote</th>\n",
       "      <th>zygotic</th>\n",
       "      <th>zymogen</th>\n",
       "      <th>zymograms</th>\n",
       "      <th>zymographc</th>\n",
       "      <th>zymography</th>\n",
       "      <th>zymoseptoria</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'ditiodiproponate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(c)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(tm)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zymograms</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zymographc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zymography</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zymoseptoria</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46063 rows × 46063 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   'ditiodiproponate  (c)  (tm)  *3  *4  *8  +-  +-1  +-2  \\\n",
       "'ditiodiproponate                  0    0     0   0   0   0   0    0    0   \n",
       "(c)                                0    0     0   0   0   0   0    0    0   \n",
       "(tm)                               0    0     0   0   0   0   0    0    0   \n",
       "*3                                 0    0     0   0   0   0   0    0    0   \n",
       "*4                                 0    0     0   0   0   1   0    0    0   \n",
       "...                              ...  ...   ...  ..  ..  ..  ..  ...  ...   \n",
       "zymograms                          0    0     0   0   0   0   0    0    0   \n",
       "zymographc                         0    0     0   0   0   0   0    0    0   \n",
       "zymography                         0    0     0   0   0   0   0    0    0   \n",
       "zymoseptoria                       0    0     0   0   0   0   0    0    0   \n",
       "zz                                 0    0     0   0   0   0   0    0    0   \n",
       "\n",
       "                   +-3  ...  zyggregator  zygosaccharomyces  zygote  zygotic  \\\n",
       "'ditiodiproponate    0  ...            0                  0       0        0   \n",
       "(c)                  0  ...            0                  0       0        0   \n",
       "(tm)                 0  ...            0                  0       0        0   \n",
       "*3                   0  ...            0                  0       0        0   \n",
       "*4                   0  ...            0                  0       0        0   \n",
       "...                ...  ...          ...                ...     ...      ...   \n",
       "zymograms            0  ...            0                  0       0        0   \n",
       "zymographc           0  ...            0                  0       0        0   \n",
       "zymography           0  ...            0                  0       0        0   \n",
       "zymoseptoria         0  ...            0                  0       0        0   \n",
       "zz                   0  ...            0                  0       0        0   \n",
       "\n",
       "                   zymogen  zymograms  zymographc  zymography  zymoseptoria  \\\n",
       "'ditiodiproponate        0          0           0           0             0   \n",
       "(c)                      0          0           0           0             0   \n",
       "(tm)                     0          0           0           0             0   \n",
       "*3                       0          0           0           0             0   \n",
       "*4                       0          0           0           0             0   \n",
       "...                    ...        ...         ...         ...           ...   \n",
       "zymograms                0          0           0           0             0   \n",
       "zymographc               0          0           0           0             0   \n",
       "zymography               0          0           0           0             0   \n",
       "zymoseptoria             0          0           0           0             0   \n",
       "zz                       0          0           0           0             0   \n",
       "\n",
       "                   zz  \n",
       "'ditiodiproponate   0  \n",
       "(c)                 0  \n",
       "(tm)                0  \n",
       "*3                  0  \n",
       "*4                  0  \n",
       "...                ..  \n",
       "zymograms           0  \n",
       "zymographc          0  \n",
       "zymography          0  \n",
       "zymoseptoria        0  \n",
       "zz                  0  \n",
       "\n",
       "[46063 rows x 46063 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "742d174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 5\n",
    "high_co_occurrence_mask = co_occurrence_matrix.values >= tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(high_co_occurrence_mask):\n",
    "    if True in row:\n",
    "        for idy, value in enumerate(row): \n",
    "            print(idx, idy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56f7b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.dat\", \"w\") as f:\n",
    "    for column in co_occurrence_matrix.columns:\n",
    "        f.write(column + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b919fad4",
   "metadata": {},
   "source": [
    "Current Work:\n",
    "The chemical identification list is too expensive to use practically and more “by-hand” methods are easier for normalizing the dataset.\n",
    "\tSpecifically, I wrote a translation guide instead of using a greek-aware lemmatizer to help make sure that chemicals shared the same name, e.g. setting the beta and the greek character beta to just be their unicode equivalent of “b”. \n",
    "\tThe unicode encoding also helps normalize the dataset although there is some concern about the removal of information\n",
    "\t\tThis reduces the vocabulary list by about 5000 terms and decreases sparsity\n",
    "The PUBMED MESH metadata is now ready to be added to the vocabulary and is roughly 10000 terms.\n",
    "\tIt is replacing the chemical list which doesn’t contain useful information and to avoid the problem of multiplying duplicate values in the vector e.g. proteome is included in both the MESH and the chemical list\n",
    "\tI am electing to use the encoding we talked about last time where each word is part of the encoding as opposed to the entire term for the highest resolution on the MESH terms even if this may introduce some ambiguity, the method is set up to handle it any of the ways we talked about however so I can change it easily\n",
    "\t\n",
    "The co-occurrence matrix looks promising thus far and I am finding a lot of values that overlap which will be useful for both LDA and for identifying words that should be bigrams instead of unigrams\n",
    "\tThe actual change from bigram to unigram words is a work in progress\n",
    "\tI also need some help selecting a tolerance for when a word should be a unigram versus a bigram, that is to say what number of co-occurrence (proximally, so next to each other) is a good cutoff\n",
    "I am currently working on calculating the Jaccard Index as well the documents to help determine if the matrices have sufficient overlap at this point for LDA\n",
    "\tDepending on the results of this I should be good to go with the next step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
